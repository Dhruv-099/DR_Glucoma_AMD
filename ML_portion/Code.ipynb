{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouPjV5GZD7la"
      },
      "source": [
        "# eye diseases classification\n",
        "\n",
        "**The following dataset is about 4 types of eye diseases and we are trying to build a model that can recognize the type of disease in 4 classifications based on the available image data of the eyes.**\n",
        "\n",
        "Our four categories include: <br>\n",
        "1. Cataract <br>\n",
        "2. Diabetic Retinopathy <br>\n",
        "3. Glaucoma <br>\n",
        "4. Normal\n",
        "\n",
        "Data link:<br>\n",
        "https://www.kaggle.com/datasets/gunavenkatdoddi/eye-diseases-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BikUQu1D7lc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split      # dividing the dataset\n",
        "from sklearn.preprocessing import LabelEncoder            # for converting str labels to number\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import random\n",
        "\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0 = all messages, 1 = filter INFO, 2 = filter WARNING, 3 = filter ERROR\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint ,Callback # type: ignore\n",
        "from tensorflow.keras import layers, models ,optimizers # type: ignore\n",
        "from tensorflow.keras.models import load_model # type: ignore\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D # type: ignore\n",
        "from tensorflow.keras.applications import EfficientNetB0 # type: ignore\n",
        "import pathlib\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_HmwrMSwD7ld",
        "outputId": "bbf0bc5d-3597-4c62-9846-5a516a94efc6"
      },
      "outputs": [],
      "source": [
        "tf.version.VERSION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx46Xq79D7ld"
      },
      "source": [
        "# Exploratory analysis of image data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6-cSdJiD7ld"
      },
      "outputs": [],
      "source": [
        "# Basic review of the photos directory\n",
        "\n",
        "def dataset_analysis(path):\n",
        "    subfolders = os.listdir(path)\n",
        "\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(path, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            files = os.listdir(subfolder_path)\n",
        "            format_dimensions_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "\n",
        "            for file in files:\n",
        "                try:\n",
        "                    file_path = os.path.join(subfolder_path, file)\n",
        "                    with Image.open(file_path) as img:\n",
        "                        image_type = img.format.upper()  # Format (e.g., JPEG, PNG)\n",
        "                        image_dimensions = img.size  # (width, height)\n",
        "                        image_mode = img.mode  # Mode (e.g., RGB, L)\n",
        "\n",
        "\n",
        "                        # Calculate bit depth\n",
        "                        if image_mode == \"1\":  # 1-bit pixels, black and white, stored with one pixel per byte\n",
        "                            bit_depth = 1\n",
        "                        elif image_mode == \"L\":  # 8-bit pixels, grayscale\n",
        "                            bit_depth = 8\n",
        "                        elif image_mode == \"P\":  # 8-bit pixels, mapped to any other mode using a color palette\n",
        "                            bit_depth = 8\n",
        "                        elif image_mode == \"RGB\":  # 8-bit pixels, true color\n",
        "                            bit_depth = 24  # 8 bits per channel\n",
        "                        elif image_mode == \"RGBA\":  # 8-bit pixels, true color with transparency mask\n",
        "                            bit_depth = 32  # 8 bits per channel\n",
        "                        elif image_mode == \"CMYK\":  # 8-bit pixels, color separation\n",
        "                            bit_depth = 32  # 8 bits per channel\n",
        "                        else:\n",
        "                            bit_depth = \"Unknown\"\n",
        "\n",
        "                        format_dimensions_counts[image_type][(image_dimensions, bit_depth)][image_mode] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
        "\n",
        "            print('--------'*10)\n",
        "            print(f\"Subfolder '{subfolder}' contains ({len(files)} files):\")\n",
        "            for format, dimensions_counts in format_dimensions_counts.items():\n",
        "                print(f\"- {sum(sum(counts.values()) for counts in dimensions_counts.values())} images of format {format}:\")\n",
        "                for (dimensions, bit_depth), counts in dimensions_counts.items():\n",
        "                    for mode, count in counts.items():\n",
        "                        print(f\"  - {count} images with dimensions {dimensions}, bit depth {bit_depth}, mode {mode}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6dvL3enGORW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t81--nsUGryz",
        "outputId": "ff2d758b-13c7-417c-a5b7-969084b6cb5b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06xlbVtYD7le",
        "outputId": "ff50bbf8-1d32-42f8-c6e6-4d7f1374d77e"
      },
      "outputs": [],
      "source": [
        "#path = r'D:\\OneDrive\\Documents\\GitHub\\DR_Glucoma_AMD\\archive'\n",
        "path= r'/content/drive/My Drive/archive'\n",
        "\n",
        "dataset_path = path\n",
        "dataset_analysis(dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "L6oynXE-D7le",
        "outputId": "e0c89e32-bb0b-411c-aa5f-1a20bc4894a4"
      },
      "outputs": [],
      "source": [
        "# Count the number of images in each directory\n",
        "subfolders = os.listdir(path)\n",
        "\n",
        "image_counts = []\n",
        "for directory in subfolders:\n",
        "    sub_dir = os.path.join(path, directory)\n",
        "    if os.path.isdir(sub_dir):\n",
        "        file_count = len(os.listdir(sub_dir))\n",
        "        image_counts.append(file_count)\n",
        "\n",
        "#Add value counts on each bar\n",
        "for i in range(len(subfolders)):\n",
        "    plt.text(i, image_counts[i], str(image_counts[i]), ha='center', va='bottom')\n",
        "\n",
        "#Set some colors\n",
        "colors = ['lightskyblue', 'mediumseagreen', 'indianred', 'orange']\n",
        "\n",
        "# Plotting the results\n",
        "plt.bar(subfolders, image_counts, color=colors)\n",
        "plt.xlabel('Directory')\n",
        "plt.xticks(rotation = 45)\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Number of Images in Each Directory')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "crhbz7DDD7le",
        "outputId": "09a76657-d60e-48b1-9cb5-b59d3dd3f0f6"
      },
      "outputs": [],
      "source": [
        "# Check the photos by size\n",
        "\n",
        "def dataset_size_analysis(path):\n",
        "    format_dimensions_counts = defaultdict(int)\n",
        "\n",
        "    subfolders = os.listdir(path)\n",
        "    for subfolder in subfolders:\n",
        "        subfolder_path = os.path.join(path, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            files = os.listdir(subfolder_path)\n",
        "\n",
        "            for file in files:\n",
        "                try:\n",
        "                    file_path = os.path.join(subfolder_path, file)\n",
        "                    with Image.open(file_path) as img:\n",
        "                        image_dimensions = img.size\n",
        "                        image_mode = img.mode\n",
        "\n",
        "                        # Calculate bit depth\n",
        "                        bit_depth = {\n",
        "                            \"1\": 1,\n",
        "                            \"L\": 8,\n",
        "                            \"P\": 8,\n",
        "                            \"RGB\": 24,\n",
        "                            \"RGBA\": 32,\n",
        "                            \"CMYK\": 32\n",
        "                        }.get(image_mode, \"Unknown\")\n",
        "\n",
        "                        # Update counts\n",
        "                        format_dimensions_counts[(image_dimensions, bit_depth)] += 1\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
        "\n",
        "    # Plotting dimensions and bit depths\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    labels = [f\"{dims}, {depth} bit\" for (dims, depth) in format_dimensions_counts]\n",
        "    sizes = list(format_dimensions_counts.values())\n",
        "    total = sum(sizes)\n",
        "    bars = plt.bar(labels, sizes, color='blue')\n",
        "    plt.xticks(rotation=45, ha=\"right\")\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Image Distribution by Dimensions and Bit Depth')\n",
        "\n",
        "    # Adding percentage labels above the bars\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, yval, f'{100 * yval/total:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Set the path to the dataset directory\n",
        "dataset_size_analysis(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "GcFsmrs1D7lf",
        "outputId": "a16c612f-551d-4dd9-d0fa-fef78a7eb0bb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def dataset_size_analysis(path):\n",
        "    # Dictionary to store counts: {subfolder: {image_size: count}}\n",
        "    folder_size_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for subfolder in os.listdir(path):\n",
        "        subfolder_path = os.path.join(path, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            for file in os.listdir(subfolder_path):\n",
        "                try:\n",
        "                    file_path = os.path.join(subfolder_path, file)\n",
        "                    with Image.open(file_path) as img:\n",
        "                        dims = img.size\n",
        "                        folder_size_counts[subfolder][dims] += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Exception processing '{file}' in '{subfolder}': {e}\")\n",
        "\n",
        "    # Create a single plot\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Determine unique image sizes across all folders for consistent coloring and grouping\n",
        "    all_sizes = set(size for sizes in folder_size_counts.values() for size in sizes)\n",
        "    all_sizes = sorted(all_sizes, key=lambda s: (s[0] * s[1]))  # Sort by area\n",
        "\n",
        "    subfolder_names = list(folder_size_counts.keys())\n",
        "    bar_width = 0.15  # Width of bars\n",
        "    indices = range(len(subfolder_names))\n",
        "\n",
        "    for i, size in enumerate(all_sizes):\n",
        "        counts = [folder_size_counts[subfolder].get(size, 0) for subfolder in subfolder_names]\n",
        "        plt.bar([index + i * bar_width for index in indices], counts, bar_width, label=f'{size[0]}x{size[1]}')\n",
        "\n",
        "    plt.xticks([index + (len(all_sizes) - 1) * bar_width / 2 for index in indices], subfolder_names, rotation=45, ha=\"right\")\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Image Size Distribution by Subfolder')\n",
        "    plt.legend(title=\"Image Size\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Set the path to the dataset directory\n",
        "dataset_size_analysis(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "6E1M7B2QD7lf",
        "outputId": "8b554b8e-3feb-45d3-e521-71cad144ccb0"
      },
      "outputs": [],
      "source": [
        "# Preview photos\n",
        "\n",
        "def random_photos_from_folders(base_folder):\n",
        "    # Walk through all directories and files in the base_folder\n",
        "    for root, dirs, files in os.walk(base_folder):\n",
        "        # Filter to get only files that are images\n",
        "        images = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        if len(images) >= 4:  # Ensure there are at least 4 images\n",
        "            selected_images = random.sample(images, 4)  # Randomly select 4 images\n",
        "\n",
        "            # Display selected images\n",
        "            fig, axs = plt.subplots(1, 4, figsize=(12, 2))  # Create a 1x4 grid of plots\n",
        "            for idx, img_name in enumerate(selected_images):\n",
        "                img_path = os.path.join(root, img_name)\n",
        "                img = Image.open(img_path)\n",
        "                axs[idx].imshow(img)\n",
        "                axs[idx].axis('off')  # Hide axes\n",
        "\n",
        "                # Extract sub-folder name from the root path\n",
        "                subfolder_name = os.path.basename(root)\n",
        "                # Set the title to include image name and sub-folder name\n",
        "                axs[idx].set_title(f\"{img_name}\\n({subfolder_name})\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "# Path to the folder containing sub-folders with images\n",
        "\n",
        "random_photos_from_folders(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEYpYLnFD7lf"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_nSIwDVD7lf",
        "outputId": "22bd4e37-07b2-4f30-8d73-1a028bbd2ac7"
      },
      "outputs": [],
      "source": [
        "# Getting the names of classes\n",
        "class_dirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
        "\n",
        "# create data path and their labeles\n",
        "data = []\n",
        "labels = []\n",
        "extensions = [\"jpg\", \"JPG\", \"jpeg\", \"JPEG\", \"png\", \"PNG\", \"bmp\", \"BMP\", \"gif\", \"GIF\"]\n",
        "\n",
        "for i in class_dirs:\n",
        "    class_label = i\n",
        "    image_files = []\n",
        "    for ext in extensions:\n",
        "        # Search for files with each extension and extend the image_files list\n",
        "        image_files.extend(glob.glob(os.path.join(path, i, f\"*.{ext}\")))\n",
        "    data.extend(image_files)\n",
        "    labels.extend([class_label] * len(image_files))\n",
        "\n",
        "# Check if lists are still empty\n",
        "if not data:\n",
        "    print(\"No files were found. Check your directory paths and file formats.\")\n",
        "else:\n",
        "    print(\"Files found and listed.\")\n",
        "\n",
        "\n",
        "# Create a DataFrame with the image paths and labels\n",
        "df = pd.DataFrame({\n",
        "'filename': data,\n",
        "'class': labels\n",
        "})\n",
        "\n",
        "\n",
        "# Shuffle the dataset by rows\n",
        "df = df.sample(frac=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NiqMQ0DVD7lg",
        "outputId": "1cf446eb-1898-4a6e-8e52-388533780980"
      },
      "outputs": [],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgIaexHMD7lg",
        "outputId": "b4f55657-dc2e-43e5-91bd-db81057a67ec"
      },
      "outputs": [],
      "source": [
        "# Convert labels to one-hot encodings\n",
        "label_encoder = LabelEncoder()\n",
        "label = label_encoder.fit_transform(df['class'])\n",
        "df['class'] = label\n",
        "\n",
        "# check number assigned to each class\n",
        "# Get the class names and corresponding integer encodings\n",
        "class_names = label_encoder.classes_\n",
        "class_numbers = label_encoder.transform(label_encoder.classes_)\n",
        "\n",
        "# Print class names with the assigned numbers\n",
        "class_dict = dict(zip(class_names, class_numbers))\n",
        "print(class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4LXdKImJD7lg",
        "outputId": "7d522332-6c60-4d67-ce8d-711264c83e47"
      },
      "outputs": [],
      "source": [
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rYr-maLD7lg"
      },
      "source": [
        "# Divide data into (train, validation, test)\n",
        "\n",
        "In dividing the data into three parts, it is important to maintain the distribution ratio of the data in the original dataset. Because I want the three parts of Train + Validation + Test to have the same ratio of data and to have the same amount of data for training for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ul_l75jD7lg",
        "outputId": "e07a1b10-1397-45de-d716-522fbfd01ddd"
      },
      "outputs": [],
      "source": [
        "# Check the balance of the classes\n",
        "print(df['class'].value_counts(normalize=True))\n",
        "print('------'*10)\n",
        "\n",
        "# Split the data into train+validation and test sets\n",
        "train_plus_val, test = train_test_split(df, test_size=0.2, stratify=df['class'], random_state=42)\n",
        "\n",
        "# Split the train+validation set into train and validation sets\n",
        "train, val = train_test_split(train_plus_val, test_size=0.25, stratify=train_plus_val['class'], random_state=42)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Now you have:\n",
        "# train: 60% of the data\n",
        "# val: 20% of the data\n",
        "# test: 20% of the data\n",
        "\n",
        "# Confirm the distribution across splits\n",
        "print(\"Training set:\")\n",
        "print(train['class'].value_counts(normalize=True))\n",
        "print('------'*10)\n",
        "\n",
        "\n",
        "print(\"Validation set:\")\n",
        "print(val['class'].value_counts(normalize=True))\n",
        "print('------'*10)\n",
        "\n",
        "\n",
        "print(\"Test set:\")\n",
        "print(test['class'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fwAKTuvD7lh"
      },
      "outputs": [],
      "source": [
        "train_links, train_labels = train['filename'].values , train['class'].values\n",
        "val_links , val_labels = val['filename'].values , val['class'].values\n",
        "test_links, test_labels = test['filename'].values , test['class'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgtRxWqMD7lh"
      },
      "source": [
        "# Load and Preprocess Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6VOXIoAD7lh"
      },
      "outputs": [],
      "source": [
        "# Create a Function to Load and Preprocess Images\n",
        "# tf.cond is a TensorFlow operation that allows for conditional execution based on the value of a tensor.\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path, label, data_augmentation=True):\n",
        "    # Read the image file\n",
        "    image = tf.io.read_file(path)\n",
        "\n",
        "    # Extract file extension\n",
        "    file_extension = tf.strings.split(path, '.')[-1]\n",
        "\n",
        "    # Decode based on file extension using tf.cond\n",
        "    def decode_jpeg():\n",
        "        return tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    def decode_png():\n",
        "        return tf.image.decode_png(image, channels=3)\n",
        "\n",
        "    def decode_bmp():\n",
        "        return tf.image.decode_bmp(image, channels=3)\n",
        "\n",
        "    def decode_gif():\n",
        "        # Decode GIF and take the first frame\n",
        "        return tf.squeeze(tf.image.decode_gif(image), axis=0)\n",
        "\n",
        "    # Handle each format\n",
        "    image = tf.cond(tf.math.equal(file_extension, 'jpg'), decode_jpeg,\n",
        "            lambda: tf.cond(tf.math.equal(file_extension, 'jpeg'), decode_jpeg,\n",
        "            lambda: tf.cond(tf.math.equal(file_extension, 'png'), decode_png,\n",
        "            lambda: tf.cond(tf.math.equal(file_extension, 'bmp'), decode_bmp,\n",
        "            lambda: tf.cond(tf.math.equal(file_extension, 'gif'), decode_gif,\n",
        "            decode_jpeg)))))\n",
        "\n",
        "    # Resize and normalize\n",
        "    image = tf.image.resize(image, [256, 256])\n",
        "    image = image / 255.0  # Normalize to [0, 1] range\n",
        "\n",
        "    # Apply data augmentation if in training mode\n",
        "    if data_augmentation == True:\n",
        "        # Randomly flip the image horizontally\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "\n",
        "        # Randomly flip the image vertically\n",
        "        image = tf.image.random_flip_up_down(image)\n",
        "\n",
        "        # Randomly rotate the image\n",
        "        image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "\n",
        "        # Randomly adjust brightness\n",
        "        image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "\n",
        "        # Randomly zoom in\n",
        "        image = tf.image.resize_with_crop_or_pad(image, 266, 266)  # Zoom in slightly\n",
        "        image = tf.image.random_crop(image, size=[256, 256, 3])\n",
        "\n",
        "        # Randomly adjust contrast\n",
        "        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "\n",
        "    return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG2sPPFHD7lh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# create TensorFlow datasets for each split\n",
        "# When loading datasets, pass the data_augmentation flag True or False to apply or skip augmentations:\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices( (train_links , train_labels) )\n",
        "train_dataset = train_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=True), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices( (val_links , val_labels) )\n",
        "val_dataset = val_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=False), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices( (test_links , test_labels) )\n",
        "test_dataset = test_dataset.map(lambda x, y: load_and_preprocess_image(x, y, data_augmentation=False), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiVgQDTwD7lh",
        "outputId": "bb9808b9-2f60-486a-cd06-90ac014dc240"
      },
      "outputs": [],
      "source": [
        "# Iterate over the dataset and print the first few elements\n",
        "for data_element, label_element in train_dataset.take(1):  # Adjust the number to print more/less\n",
        "    print(f\"Data: {data_element.numpy()}, Label: {label_element.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eALGI2L7D7lh",
        "outputId": "0b8e8fa9-09c9-48b3-a34d-4d0fd7014a33"
      },
      "outputs": [],
      "source": [
        "# Iterate over the dataset and print the first few elements\n",
        "for data_element, label_element in train_dataset.take(1):  # Adjust the number to print more/less\n",
        "    print(f\"Data: {data_element.numpy().shape}, Label: {label_element.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Huy_W0CID7lh"
      },
      "outputs": [],
      "source": [
        "#prepare your datasets for model training and evaluation\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.prefetch(buffer_size= tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE-4QKvnD7li"
      },
      "source": [
        "# Create Custom Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 866
        },
        "id": "VPH21ZSpD7li",
        "outputId": "4d7498d5-889c-4293-8310-64b68702b1be"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = models.Sequential([\n",
        "    # First Block\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', input_shape=(256, 256, 3), padding='same'),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "    # Second Block\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Second Block\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "    # Second Block\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.Conv2D(256, (3, 3), activation='relu',padding='valid'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "\n",
        "    # Global Average Pooling instead of Flatten\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    layers.Dense(512,activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(len(class_names), activation='softmax')  # Output layer\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf9Io9shD7li",
        "outputId": "9e70bb21-a03e-44d4-baae-12472f724f2c"
      },
      "outputs": [],
      "source": [
        "# Define the EarlyStopping callback to monitor the validation accuracy\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',  # Monitoring validation accuracy\n",
        "    patience=12,  # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,\n",
        "    mode='max',  # Stops training when the quantity monitored has stopped increasing\n",
        "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=r'/content/drive/My Drive/archive/best_model_custom.keras',  # Path to save the model file\n",
        "    monitor='val_loss',  # Monitoring validation loss\n",
        "    verbose=1,\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode='min'  # Save the model when the monitored metric has minimized\n",
        ")\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x = train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    epochs = 200,\n",
        "    callbacks=[early_stopping , model_checkpoint]  # Add the EarlyStopping callback\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "d0qL6OOnD7li",
        "outputId": "2418a530-90b0-4b5f-ce75-764af69588ad"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(history.history['accuracy'],color=\"#E74C3C\", marker='o')\n",
        "plt.plot(history.history['val_accuracy'], color='#641E16', marker='h')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(history.history['loss'],color=\"#E74C3C\", marker='o')\n",
        "plt.plot(history.history['val_loss'], color='#641E16', marker='h')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend( ['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rYdxd6DD7li",
        "outputId": "6d440038-9a91-48aa-f278-de99ff1ca205"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(r'/content/drive/My Drive/archive/best_model_custom.keras')\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "train_loss, train_accuracy = best_model.evaluate(train_dataset)\n",
        "val_loss, val_accuracy = best_model.evaluate(val_dataset)\n",
        "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"train loss: {train_loss}\")\n",
        "print(f\"train accuracy: {train_accuracy}\")\n",
        "print('----'*6)\n",
        "print(f\"val loss: {val_loss}\")\n",
        "print(f\"val accuracy: {val_accuracy}\")\n",
        "print('----'*6)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_IrBuLZD7li",
        "outputId": "fe16f262-8e3d-480f-ad51-f45871f6863c"
      },
      "outputs": [],
      "source": [
        "# Assuming best_model is your trained Keras model\n",
        "\n",
        "# Get the predicted labels from the model\n",
        "y_pred = np.argmax( best_model.predict(test_dataset) , axis=1 ) # Convert probabilities to class indices\n",
        "y_true = test_labels\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "\n",
        "# Get the class labels from the LabelEncoder\n",
        "class_labels = label_encoder.classes_\n",
        "\n",
        "# Compute classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "1FG8CkQhD7li",
        "outputId": "c42a29f0-2051-48f6-b1dc-f5d5cb3b4838"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "print('Total Number Of Test data: ', len(test_labels))\n",
        "\n",
        "sn.set_style(\"white\")\n",
        "def plot_confusion_matrix(conf_mat, classes):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(7,7)) # change the plot size\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=classes)\n",
        "    disp = disp.plot(include_values=True,cmap='viridis', ax=ax, xticks_rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Get your confusion matrix\n",
        "conf_mat = conf_mat\n",
        "\n",
        "# Using label_encoder.classes_ guarantees that class_names matches\n",
        "# the order that was used during the one-hot encoding process\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Now plot using the function\n",
        "plot_confusion_matrix(conf_mat, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "0BxRZZWYD7lj",
        "outputId": "693d5f4b-4f79-4242-ee62-939db69a2479"
      },
      "outputs": [],
      "source": [
        "# probability explanation in below function:\n",
        "# For example, if the model predicts an image as class B with a probability of 0.7 (or 70%),\n",
        "# the plot will show \"Probability: 70%\".\n",
        "# This means the model is 70% confident that the image belongs to class B.\n",
        "\n",
        "\n",
        "def plot_test_predictions(model, test_dataset, class_labels, num_images=20):\n",
        "    \"\"\"\n",
        "    Plots the predictions of a model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model to be used for prediction.\n",
        "    - test_dataset: TensorFlow dataset containing the test images and labels.\n",
        "    - class_labels: List of class labels.\n",
        "    - num_images: Number of test images to plot (default is 20).\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize lists to accumulate images and labels\n",
        "    images = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    pred_probs = []\n",
        "\n",
        "    for batch_images, batch_labels in test_dataset:\n",
        "        # Predict on the batch\n",
        "        batch_pred_probs = model.predict(batch_images)\n",
        "        batch_pred_labels = np.argmax(batch_pred_probs, axis=1)\n",
        "\n",
        "        # Accumulate images and labels\n",
        "        images.extend(batch_images)\n",
        "        true_labels.extend(batch_labels)\n",
        "        pred_labels.extend(batch_pred_labels)\n",
        "        pred_probs.extend(np.max(batch_pred_probs, axis=1) * 100)\n",
        "\n",
        "        if len(images) >= num_images:\n",
        "            break\n",
        "\n",
        "    # Plot the images with predictions\n",
        "    plt.figure(figsize=(15, 20))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        actual_label = class_labels[true_labels[i]]\n",
        "        predicted_label = class_labels[pred_labels[i]]\n",
        "        probability = pred_probs[i]  # Probability of the predicted class\n",
        "\n",
        "        color = 'green' if actual_label == predicted_label else 'red'\n",
        "        plt.title(f\"Actual Label: {actual_label}\\nPrediction: {predicted_label}\\nProbability: {probability:.2f}%\",\n",
        "                  color=color, fontsize=12)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Use the function\n",
        "plot_test_predictions(best_model, test_dataset, class_labels=class_names, num_images=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjT4Wa5fD7lj"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "By setting `include_top=False`, the last fully connected layers are removed and only the base convolutional network is left, which is used when a pre-trained network is required to serve as a feature extractor in transfer learning setup followed by subsequent training of new top layer specific to your dataset.\n",
        "\n",
        "When you set `base_model.trainable = True`, all the layers in the base model become trainable. In this case, these layers will have their weights updated during training. This method is often used in situations where you have a lot of training data and wish to fine-tune the entire model on your new data for perhaps better performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Khybp3adD7lj",
        "outputId": "66657257-708f-4e79-f3b0-ddce368f2e70"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the number of classes (make sure class_names is defined correctly)\n",
        "num_classes = len(class_names)  # Ensure this is correct\n",
        "\n",
        "# Load the EfficientNetB0 model pre-trained on ImageNet, without the top layers\n",
        "base_model = EfficientNetB0(input_shape=(256, 256, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Make all layers in the base model trainable\n",
        "base_model.trainable = True\n",
        "\n",
        "# Create your custom model on top of the pre-trained EfficientNetB0\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPool2D((2, 2)),\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(num_classes, activation='softmax')  # Adjust num_classes based on your dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE1F4WV_D7lj"
      },
      "source": [
        "Here I tried to use the .keras extension to save the model, but after saving and reloading in transfer learning mode, the weights were not saved correctly, while it worked fine in non-transfer mode. I didn't understand the reason, so I made a custom function to use the .h5 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gd5bf0oD7lj",
        "outputId": "e7280903-140e-4c48-b38b-e765bf8ff1ba"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------#\n",
        "\n",
        "class CustomEarlyStoppingAndCheckpoint(Callback):\n",
        "    def __init__(self, save_path, patience=12, verbose=1, save_best_only=True):\n",
        "        super(CustomEarlyStoppingAndCheckpoint, self).__init__()\n",
        "        self.save_path = save_path\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.save_best_only = save_best_only\n",
        "        self.best_weights = None\n",
        "        self.best_acc = -np.Inf\n",
        "        self.best_loss = np.Inf\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        val_loss = logs.get('val_loss')\n",
        "        val_acc = logs.get('val_accuracy')\n",
        "        if val_acc is None or val_loss is None:\n",
        "            return\n",
        "\n",
        "        # Checkpoint for best loss\n",
        "        if val_loss < self.best_loss:\n",
        "            self.best_loss = val_loss\n",
        "            if self.save_best_only:\n",
        "                self.model.save(self.save_path, include_optimizer=True)\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"\\nEpoch {epoch + 1}: val_loss improved to {val_loss:.4f}, saving model to {self.save_path}\")\n",
        "\n",
        "        # Early stopping for best accuracy\n",
        "        if val_acc > self.best_acc:\n",
        "            self.best_acc = val_acc\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            self.wait = 0\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                if self.verbose > 0:\n",
        "                    print(f\"\\nEpoch {epoch + 1}: early stopping\")\n",
        "                if self.best_weights is not None:\n",
        "                    self.model.set_weights(self.best_weights)\n",
        "                    if self.verbose > 0:\n",
        "                        print(\"Restoring model weights from the end of the best epoch based on accuracy.\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
        "            print(f\"Epoch {self.stopped_epoch + 1}: early stopping triggered\")\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------#\n",
        "\n",
        "# Usage of the custom callback\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callbacks = [\n",
        "    CustomEarlyStoppingAndCheckpoint(\n",
        "        save_path=r'/content/drive/My Drive/archive/best_model_transfer.h5',#file\n",
        "        patience=12,\n",
        "        verbose=1,\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(\n",
        "    x = train_dataset,\n",
        "    validation_data = val_dataset,\n",
        "    epochs = 50,\n",
        "    callbacks= callbacks # Add the EarlyStopping callback\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "mEozXAqQD7lk",
        "outputId": "52a1a4c2-ed49-497e-df65-35ec51eb9fd8"
      },
      "outputs": [],
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(history.history['accuracy'],color=\"#E74C3C\", marker='o')\n",
        "plt.plot(history.history['val_accuracy'], color='#641E16', marker='h')\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(history.history['loss'],color=\"#E74C3C\", marker='o')\n",
        "plt.plot(history.history['val_loss'], color='#641E16', marker='h')\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend( ['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRITA0cHD7lk",
        "outputId": "d29f527a-9a05-423f-847a-9923146760d0"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "# If the best model is captured by the early stopping mechanism then best_model = model\n",
        "# best_model = model\n",
        "\n",
        "\n",
        "\n",
        "# Load the saved model\n",
        "best_model = load_model('/content/drive/My Drive/archive/best_model_transfer.h5',\n",
        "custom_objects={'CustomEarlyStoppingAndCheckpoint': CustomEarlyStoppingAndCheckpoint}  # Replace with your custom objects if any\n",
        "                            )\n",
        "best_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Evaluate the model\n",
        "train_loss, train_accuracy = best_model.evaluate(train_dataset)\n",
        "val_loss, val_accuracy = best_model.evaluate(val_dataset)\n",
        "test_loss, test_accuracy = best_model.evaluate(test_dataset)\n",
        "\n",
        "print(f\"Train loss: {train_loss}\")\n",
        "print(f\"Train accuracy: {train_accuracy}\")\n",
        "print('----' * 6)\n",
        "print(f\"Val loss: {val_loss}\")\n",
        "print(f\"Val accuracy: {val_accuracy}\")\n",
        "print('----' * 6)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83fJRVVMD7lk",
        "outputId": "40e582db-ff48-47ff-a2cb-991afc8b1d9f"
      },
      "outputs": [],
      "source": [
        "# Assuming best_model is your trained Keras model\n",
        "\n",
        "# Get the predicted labels from the model\n",
        "y_pred = np.argmax( best_model.predict(test_dataset) , axis=1 ) # Convert probabilities to class indices\n",
        "y_true = test_labels\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_mat = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "\n",
        "# Get the class labels from the LabelEncoder\n",
        "class_labels = label_encoder.classes_\n",
        "\n",
        "# Compute classification report\n",
        "report = classification_report(y_true, y_pred, target_names=class_labels)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "id": "GS9UQlm6D7lk",
        "outputId": "dd46f3b4-1254-4269-accd-f7b693375f1e"
      },
      "outputs": [],
      "source": [
        "#Confusion matrix\n",
        "print('Total Number Of Test data: ', len(test_labels))\n",
        "\n",
        "sn.set_style(\"white\")\n",
        "def plot_confusion_matrix(conf_mat, classes):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    \"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(7,7)) # change the plot size\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=classes)\n",
        "    disp = disp.plot(include_values=True,cmap='viridis', ax=ax, xticks_rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "# Get your confusion matrix\n",
        "conf_mat = conf_mat\n",
        "\n",
        "# Using label_encoder.classes_ guarantees that class_names matches\n",
        "# the order that was used during the one-hot encoding process\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "# Now plot using the function\n",
        "plot_confusion_matrix(conf_mat, class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Bn4aHXgyD7lk",
        "outputId": "4458caf8-d90b-4916-fe55-cc7a64827db4"
      },
      "outputs": [],
      "source": [
        "# probability explanation in below function:\n",
        "# For example, if the model predicts an image as class B with a probability of 0.7 (or 70%),\n",
        "# the plot will show \"Probability: 70%\".\n",
        "# This means the model is 70% confident that the image belongs to class B.\n",
        "\n",
        "def plot_test_predictions(model, test_dataset, class_labels, num_images=20):\n",
        "    \"\"\"\n",
        "    Plots the predictions of a model on the test dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained Keras model to be used for prediction.\n",
        "    - test_dataset: TensorFlow dataset containing the test images and labels.\n",
        "    - class_labels: List of class labels.\n",
        "    - num_images: Number of test images to plot (default is 20).\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize lists to accumulate images and labels\n",
        "    images = []\n",
        "    true_labels = []\n",
        "    pred_labels = []\n",
        "    pred_probs = []\n",
        "\n",
        "    for batch_images, batch_labels in test_dataset:\n",
        "        # Predict on the batch\n",
        "        batch_pred_probs = model.predict(batch_images)\n",
        "        batch_pred_labels = np.argmax(batch_pred_probs, axis=1)\n",
        "\n",
        "        # Accumulate images and labels\n",
        "        images.extend(batch_images)\n",
        "        true_labels.extend(batch_labels)\n",
        "        pred_labels.extend(batch_pred_labels)\n",
        "        pred_probs.extend(np.max(batch_pred_probs, axis=1) * 100)\n",
        "\n",
        "        if len(images) >= num_images:\n",
        "            break\n",
        "\n",
        "    # Plot the images with predictions\n",
        "    plt.figure(figsize=(15, 20))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        actual_label = class_labels[true_labels[i]]\n",
        "        predicted_label = class_labels[pred_labels[i]]\n",
        "        probability = pred_probs[i]  # Probability of the predicted class\n",
        "\n",
        "        color = 'green' if actual_label == predicted_label else 'red'\n",
        "        plt.title(f\"Actual Label: {actual_label}\\nPrediction: {predicted_label}\\nProbability: {probability:.2f}%\", color=color, fontsize=12)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Use the function\n",
        "plot_test_predictions(best_model, test_dataset, class_labels=class_names, num_images=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVAB4SBUw9I1",
        "outputId": "2471cad2-5218-4e96-8454-d4a99e23062a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
